import streamlit as st
import requests
import google.generativeai as genai
from googleapiclient.discovery import build
import concurrent.futures
from datetime import datetime

# ==========================================
# 1. ç³»çµ±é…ç½®èˆ‡ API è¨­å®š
# ==========================================

st.set_page_config(
    page_title="YouTube æˆ°ç•¥å…§å®¹åˆ‡å…¥åˆ†æå„€ v3",
    page_icon="ğŸ¯",
    layout="wide"
)

# å›ºå®šçˆ¬å­—å¹•ç”¨çš„æ¨¡å‹ï¼ˆä½æˆæœ¬ï¼‰
TRANSCRIPT_MODEL = "gemini-2.5-flash"

# ç­–ç•¥æ¨¡çµ„å®šç¾©
STRATEGY_MODULES = {
    "related": {
        "name": "ğŸ”— ç›¸é—œç­–ç•¥ (Related)",
        "description": "åˆ©ç”¨ç¾æœ‰ç†±é–€å½±ç‰‡çš„æµé‡ï¼Œåšé—œè¯å…§å®¹",
        "prompt": """
## ğŸ”— ç›¸é—œç­–ç•¥ (Related)
å¦‚ä½•åˆ©ç”¨é€™äº›å½±ç‰‡çš„ç¾æœ‰ç†±åº¦ï¼Ÿ

è«‹æä¾›ï¼š
1. **é—œè¯æ¨™é¡Œå»ºè­°** (3å€‹ï¼Œèåˆå¤šå€‹é—œéµå­—)
2. **é—œéµå­—ä½ˆå±€å»ºè­°**ï¼šä¸»é—œéµå­—ã€é•·å°¾é—œéµå­—ã€æ¨™ç±¤å»ºè­°
3. **å›æ‡‰å½±ç‰‡ç­–ç•¥**ï¼šå¦‚ä½•åšã€Œå›æ‡‰å½±ç‰‡ã€æˆ–ã€Œè£œå……è§€é»ã€
4. **SEO å„ªåŒ–å»ºè­°**ï¼šæ¨™é¡Œã€æè¿°ã€ç¸®åœ–çš„å„ªåŒ–æ–¹å‘
"""
    },
    "trending": {
        "name": "ğŸ”¥ è¹­æµé‡ç­–ç•¥ (Trending)",
        "description": "å¿«é€Ÿè¹­ç†±é–€è©±é¡Œçš„æµé‡",
        "prompt": """
## ğŸ”¥ è¹­æµé‡ç­–ç•¥ (Trending)
å¦‚ä½•å¿«é€Ÿè¹­åˆ°é€™äº›ç†±é–€è©±é¡Œçš„æµé‡ï¼Ÿ

è«‹æä¾›ï¼š
1. **æ™‚æ•ˆæ€§åˆ‡å…¥**ï¼šç›®å‰æœ€ç†±çš„è­°é¡Œé»æ˜¯ä»€éº¼ï¼Ÿ
2. **å¿«é€Ÿè£½ä½œå»ºè­°**ï¼šå¦‚ä½•åœ¨ 24-48 å°æ™‚å…§ç”¢å‡ºç›¸é—œå…§å®¹
3. **æ¨™é¡Œå…¬å¼**ï¼š3 å€‹èƒ½è¹­æµé‡çš„æ¨™é¡Œç¯„æœ¬
4. **é¢¨éšªè©•ä¼°**ï¼šé€™å€‹è©±é¡Œçš„ç†±åº¦é€±æœŸé ä¼°
5. **å·®ç•°åŒ–è§’åº¦**ï¼šå¦‚ä½•åœ¨çœ¾å¤šè¹­æµé‡å½±ç‰‡ä¸­è„«ç©è€Œå‡º
"""
    },
    "extended": {
        "name": "ğŸ“ˆ å»¶ä¼¸ç­–ç•¥ (Extended)",
        "description": "æ·±å…¥æ¢è¨ç«¶å“æ²’è¬›æ¸…æ¥šçš„å…§å®¹",
        "prompt": """
## ğŸ“ˆ å»¶ä¼¸ç­–ç•¥ (Extended)
é€™äº›å½±ç‰‡æ²’è¬›æ¸…æ¥šçš„æ˜¯ä»€éº¼ï¼Ÿ

è«‹æä¾›ï¼š
1. **æ·±åº¦å»¶ä¼¸é»** (åˆ—èˆ‰ 3-5 é»)ï¼šç«¶å“å½±ç‰‡æåˆ°ä½†æ²’æ·±å…¥çš„ä¸»é¡Œ
2. **å¯¦ä½œæ­¥é©Ÿè£œå……**ï¼šç«¶å“åªè¬›æ¦‚å¿µï¼Œä½ å¯ä»¥è£œå……çš„å¯¦éš›æ“ä½œ
3. **æ•¸æ“šä½è­‰æ–¹å‘**ï¼šå¯ä»¥ç”¨ä»€éº¼æ•¸æ“šè®“å…§å®¹æ›´æœ‰èªªæœåŠ›
4. **æ¡ˆä¾‹è£œå……**ï¼šå¯ä»¥æ–°å¢å“ªäº›æ¡ˆä¾‹è®“å…§å®¹æ›´è±å¯Œ
5. **é€²éšå…§å®¹**ï¼šé©åˆé€²éšè§€çœ¾çš„å»¶ä¼¸ä¸»é¡Œ
"""
    },
    "superior": {
        "name": "ğŸš€ è¶…è¶Šç­–ç•¥ (Superior)",
        "description": "è£½ä½œå“è³ªæ›´é«˜çš„å½±ç‰‡",
        "prompt": """
## ğŸš€ è¶…è¶Šç­–ç•¥ (Superior)
å¦‚ä½•è£½ä½œä¸€æ”¯å“è³ªæ›´é«˜çš„å½±ç‰‡ï¼Ÿ

è«‹æä¾›ï¼š
1. **è¦–è¦ºåŒ–å‡ç´š**ï¼šå¦‚ä½•ç”¨æ›´å¥½çš„è¦–è¦ºå‘ˆç¾ï¼ˆå‹•ç•«ã€åœ–è¡¨ã€å¯¦æ‹ï¼‰
2. **ç¨ç‰¹è§€é»**ï¼šç«¶å“éƒ½æ²’æåˆ°çš„ç¨ç‰¹åˆ‡å…¥è§’åº¦
3. **æƒ…ç·’å…±é³´è¨­è¨ˆ**ï¼šå¦‚ä½•è¨­è¨ˆèƒ½å¼•ç™¼è§€çœ¾å…±é³´çš„æ©‹æ®µ
4. **æ¬Šå¨æ€§å»ºç«‹**ï¼šå¦‚ä½•å±•ç¾ä½ æ¯”ç«¶å“æ›´å°ˆæ¥­
5. **è£½ä½œè¦æ ¼å»ºè­°**ï¼šç‰‡é•·ã€ç¯€å¥ã€æ®µè½çµæ§‹
6. **è…³æœ¬å¤§ç¶±**ï¼šå®Œæ•´çš„å½±ç‰‡è…³æœ¬çµæ§‹å»ºè­°
"""
    },
    "localization": {
        "name": "ğŸŒ æ¬é‹ç­–ç•¥ (Localization)",
        "description": "å°‡è‹±æ–‡å„ªè³ªå…§å®¹æœ¬åœ°åŒ–",
        "prompt": """
## ğŸŒ æ¬é‹ç­–ç•¥ (Localization)
å¦‚ä½•å°‡è‹±æ–‡å¸‚å ´çš„å„ªè³ªå…§å®¹æœ¬åœ°åŒ–ï¼Ÿ

è«‹æä¾›ï¼š
1. **å¯æ¬é‹å…§å®¹**ï¼šå“ªäº›è‹±æ–‡å½±ç‰‡çš„å…§å®¹å€¼å¾—æœ¬åœ°åŒ–ï¼Ÿ
2. **æœ¬åœ°åŒ–èª¿æ•´**ï¼šéœ€è¦é‡å°å°ç£/è¯èªå¸‚å ´åšå“ªäº›èª¿æ•´ï¼Ÿ
3. **åœ¨åœ°æ¡ˆä¾‹æ›¿æ›**ï¼šå¯ä»¥ç”¨ä»€éº¼æœ¬åœ°æ¡ˆä¾‹æ›¿æ›åœ‹å¤–æ¡ˆä¾‹ï¼Ÿ
4. **æ–‡åŒ–é©é…**ï¼šæœ‰å“ªäº›æ–‡åŒ–å·®ç•°éœ€è¦æ³¨æ„ï¼Ÿ
5. **åˆè¦å»ºè­°**ï¼šå¦‚ä½•é¿å…ç‰ˆæ¬Šå•é¡Œï¼Œåšå‡ºåŸå‰µæ€§å…§å®¹
6. **åŠ å€¼æ–¹å‘**ï¼šå¦‚ä½•åœ¨æ¬é‹åŸºç¤ä¸Šå¢åŠ ç¨ç‰¹åƒ¹å€¼
"""
    },
    "comprehensive": {
        "name": "ğŸ“Š ç¶œåˆè©•æ¯” (Comprehensive)",
        "description": "æ•´åˆæ‰€æœ‰ç«¶å“çš„å„ªç¼ºé»åˆ†æ",
        "prompt": """
## ğŸ“Š ç¶œåˆè©•æ¯” (Comprehensive)
æ•´åˆæ‰€æœ‰ç«¶å“å½±ç‰‡çš„å„ªç¼ºé»åˆ†æ

è«‹æä¾›ï¼š
1. **ç«¶å“çŸ©é™£**ï¼šç”¨è¡¨æ ¼åˆ—å‡ºå„å½±ç‰‡çš„å„ªç¼ºé»æ¯”è¼ƒ
2. **å…§å®¹è¦†è“‹åº¦**ï¼šå“ªäº›ä¸»é¡Œè¢«å¤šæ¬¡æåˆ°ï¼Ÿå“ªäº›è¢«å¿½ç•¥ï¼Ÿ
3. **è§€çœ¾åæ‡‰åˆ†æ**ï¼šå¾è§€çœ‹æ•¸æ¨æ¸¬è§€çœ¾åå¥½
4. **æœ€ä½³å¯¦è¸**ï¼šç¶œåˆå„ç«¶å“çš„æœ€ä½³åšæ³•
5. **å¸‚å ´ç¼ºå£ç¸½çµ**ï¼šæ•´é«”å¸‚å ´é‚„ç¼ºä»€éº¼å…§å®¹ï¼Ÿ
6. **å„ªå…ˆé †åºå»ºè­°**ï¼šå¦‚æœåªèƒ½åšä¸€æ”¯å½±ç‰‡ï¼Œæ‡‰è©²é¸ä»€éº¼ä¸»é¡Œï¼Ÿ
"""
    }
}

# å´é‚Šæ¬„é…ç½®
with st.sidebar:
    st.header("ğŸ”‘ API é‡‘é‘°è¨­å®š")
    GEMINI_API_KEY = st.text_input("Gemini API Key", type="password")
    YOUTUBE_API_KEY = st.text_input("YouTube Data API Key", type="password", help="éœ€è‡³ Google Cloud Console å•Ÿç”¨ YouTube Data API v3")
    
    st.markdown("---")
    st.markdown("**åˆ†ææ¨¡å‹è¨­å®š**")
    MODEL_VERSION = st.selectbox(
        "ç­–ç•¥åˆ†ææ¨¡å‹", 
        ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"],
        help="ç”¨æ–¼æ„åœ–åˆ†æèˆ‡ç­–ç•¥ç”Ÿæˆ"
    )
    st.caption(f"ğŸ’¡ å­—å¹•çˆ¬å–å›ºå®šä½¿ç”¨ `{TRANSCRIPT_MODEL}`")
    
    st.markdown("---")
    st.markdown("**æœå°‹è¨­å®š**")
    MAX_RESULTS_PER_KEYWORD = st.slider("æ¯å€‹é—œéµå­—æŠ“å–å½±ç‰‡æ•¸", 3, 10, 5)
    MAX_CONCURRENT_AI = st.slider("åŒæ™‚çˆ¬å–å½±ç‰‡æ•¸", 1, 5, 3, help="å¤ªé«˜å¯èƒ½è§¸ç™¼ API é™åˆ¶")
    
    st.markdown("---")
    st.markdown("**ğŸŒ è‹±æ–‡å¸‚å ´åŠŸèƒ½**")
    ENABLE_ENGLISH = st.checkbox("å•Ÿç”¨è‹±æ–‡å¸‚å ´æ¯”å°", value=False, help="å°‡é—œéµå­—ç¿»è­¯æˆè‹±æ–‡ï¼Œæœå°‹è‹±æ–‡å½±ç‰‡")
    
    st.markdown("---")
    st.markdown("**æµç¨‹é€²åº¦**")
    step1_done = "search_results" in st.session_state and (st.session_state.search_results.get('zh') or st.session_state.search_results.get('en'))
    step2_done = "video_analyses" in st.session_state and (st.session_state.video_analyses.get('zh') or st.session_state.video_analyses.get('en'))
    step3_done = "strategy_results" in st.session_state and st.session_state.strategy_results
    
    st.markdown(f"{'âœ…' if step1_done else 'â¬œ'} STEP 1: æœå°‹èˆ‡æ„åœ–åˆ†æ")
    st.markdown(f"{'âœ…' if step2_done else 'â¬œ'} STEP 2: AI çˆ¬å–å½±ç‰‡å…§å®¹")
    st.markdown(f"{'âœ…' if step3_done else 'â¬œ'} STEP 3: ç­–ç•¥æ¨¡çµ„åˆ†æ")

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼åº«
# ==========================================

def get_youtube_suggestions(keyword, lang="zh-TW"):
    """æŠ“å– YouTube æœå°‹ä¸‹æ‹‰é¸å–®çš„è‡ªå‹•å®Œæˆé—œéµå­—"""
    try:
        url = "http://suggestqueries.google.com/complete/search"
        params = {
            "client": "firefox",
            "ds": "yt",
            "q": keyword,
            "hl": lang
        }
        response = requests.get(url, params=params, timeout=2)
        data = response.json()
        if data and len(data) > 1:
            return data[1]
        return []
    except Exception:
        return []

def translate_keyword_to_english(api_key, keyword, model_version="gemini-2.5-flash"):
    """ä½¿ç”¨ AI å°‡é—œéµå­—ç¿»è­¯æˆè‹±æ–‡"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_version)
    
    prompt = f"""
    è«‹å°‡ä»¥ä¸‹ä¸­æ–‡é—œéµå­—ç¿»è­¯æˆæœ€é©åˆåœ¨ YouTube æœå°‹çš„è‹±æ–‡é—œéµå­—ã€‚
    
    ä¸­æ–‡é—œéµå­—ï¼š{keyword}
    
    è¦æ±‚ï¼š
    1. ç¿»è­¯è¦ç¬¦åˆè‹±æ–‡ YouTube çš„æœå°‹ç¿’æ…£
    2. å¦‚æœæœ‰å¤šç¨®ç¿»è­¯æ–¹å¼ï¼Œé¸æ“‡æœå°‹é‡æœ€å¤§çš„ç‰ˆæœ¬
    3. åªå›è¦†è‹±æ–‡é—œéµå­—ï¼Œä¸è¦å…¶ä»–è§£é‡‹
    4. å¦‚æœé—œéµå­—æœ¬èº«å°±æ˜¯è‹±æ–‡æˆ–å°ˆæœ‰åè©ï¼Œä¿æŒåŸæ¨£
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return keyword  # ç¿»è­¯å¤±æ•—å°±ç”¨åŸæœ¬çš„

def batch_translate_keywords(api_key, keywords_list, model_version="gemini-2.5-flash"):
    """æ‰¹æ¬¡ç¿»è­¯é—œéµå­—"""
    translations = {}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_to_kw = {
            executor.submit(translate_keyword_to_english, api_key, kw, model_version): kw 
            for kw in keywords_list
        }
        
        for future in concurrent.futures.as_completed(future_to_kw):
            original_kw = future_to_kw[future]
            try:
                translated = future.result()
                translations[original_kw] = translated
            except Exception:
                translations[original_kw] = original_kw
    
    return translations

def search_youtube_api(api_key, query, max_results=5, region_code="TW", relevance_language=None):
    """ä½¿ç”¨ YouTube Data API ç²å–å½±ç‰‡åˆ—è¡¨èˆ‡è©³ç´°æ•¸æ“š"""
    try:
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        search_params = {
            'q': query,
            'part': 'id,snippet',
            'maxResults': max_results,
            'type': 'video',
            'order': 'relevance',
            'regionCode': region_code
        }
        
        if relevance_language:
            search_params['relevanceLanguage'] = relevance_language
        
        search_response = youtube.search().list(**search_params).execute()

        video_ids = [item['id']['videoId'] for item in search_response['items']]
        
        if not video_ids:
            return []
        
        stats_response = youtube.videos().list(
            part='snippet,statistics',
            id=','.join(video_ids)
        ).execute()

        results = []
        for item in stats_response['items']:
            results.append({
                'id': item['id'],
                'title': item['snippet']['title'],
                'description': item['snippet']['description'],
                'channel': item['snippet']['channelTitle'],
                'publish_time': item['snippet']['publishedAt'],
                'view_count': int(item['statistics'].get('viewCount', 0)),
                'thumbnail': item['snippet']['thumbnails']['high']['url'],
                'url': f"https://www.youtube.com/watch?v={item['id']}",
                'source_keyword': query,
                'language': relevance_language or 'zh'
            })
        
        return results

    except Exception as e:
        st.error(f"YouTube API éŒ¯èª¤ ({query}): {e}")
        return []

def search_multiple_keywords(api_key, keywords_list, max_results_per_keyword, lang="zh"):
    """æ‰¹æ¬¡æœå°‹å¤šå€‹é—œéµå­—"""
    all_results = []
    seen_ids = set()
    
    region_code = "TW" if lang == "zh" else "US"
    relevance_language = "zh-Hant" if lang == "zh" else "en"
    
    for keyword in keywords_list:
        results = search_youtube_api(
            api_key, keyword, max_results_per_keyword, 
            region_code=region_code, 
            relevance_language=relevance_language
        )
        for video in results:
            if video['id'] not in seen_ids:
                seen_ids.add(video['id'])
                video['market'] = lang  # æ¨™è¨˜å¸‚å ´
                all_results.append(video)
    
    return all_results

# ==========================================
# 3. AI åˆ†æå‡½å¼
# ==========================================

def extract_video_content_via_ai(api_key, video_info):
    """ç”¨ AI ç›´æ¥çˆ¬å–å–®æ”¯ YouTube å½±ç‰‡çš„å…§å®¹æ‘˜è¦"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(TRANSCRIPT_MODEL)
    
    video_url = video_info['url']
    video_title = video_info['title']
    market = video_info.get('market', 'zh')
    
    lang_instruction = "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”" if market == "zh" else "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼ˆå½±ç‰‡æ˜¯è‹±æ–‡çš„ï¼Œä½†åˆ†æè«‹ç”¨ä¸­æ–‡ï¼‰"
    
    prompt = f"""
    è«‹åˆ†æé€™æ”¯ YouTube å½±ç‰‡çš„å®Œæ•´å…§å®¹ï¼š
    å½±ç‰‡ç¶²å€ï¼š{video_url}
    å½±ç‰‡æ¨™é¡Œï¼š{video_title}
    
    è«‹æä¾›ï¼š
    1. **å½±ç‰‡ä¸»é¡Œ**ï¼šé€™æ”¯å½±ç‰‡åœ¨è¬›ä»€éº¼ï¼Ÿ(1-2å¥)
    2. **æ ¸å¿ƒè«–é»**ï¼šå½±ç‰‡çš„ä¸»è¦è§€é»æˆ–æ•™å­¸é‡é» (æ¢åˆ—3-5é»)
    3. **å…§å®¹çµæ§‹**ï¼šå½±ç‰‡çš„æ®µè½æ¶æ§‹ (é–‹é ­è¬›ä»€éº¼ã€ä¸­é–“è¬›ä»€éº¼ã€çµå°¾è¬›ä»€éº¼)
    4. **é—œéµé‡‘å¥**ï¼šå½±ç‰‡ä¸­æœ‰åƒ¹å€¼çš„å¥å­æˆ–è§€é» (2-3å¥)
    5. **ç›®æ¨™å—çœ¾**ï¼šé€™æ”¯å½±ç‰‡æ˜¯æ‹çµ¦èª°çœ‹çš„ï¼Ÿ
    6. **å…§å®¹ç¼ºå£**ï¼šé€™æ”¯å½±ç‰‡æ²’è¬›åˆ°ä½†è§€çœ¾å¯èƒ½æƒ³çŸ¥é“çš„ (1-2é»)
    7. **ç¨ç‰¹åƒ¹å€¼**ï¼šé€™æ”¯å½±ç‰‡ç›¸æ¯”å…¶ä»–åŒé¡å½±ç‰‡çš„ç¨ç‰¹ä¹‹è™•
    
    {lang_instruction}ï¼Œæ ¼å¼æ¸…æ™°ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        return {
            'video_id': video_info['id'],
            'title': video_title,
            'url': video_url,
            'view_count': video_info['view_count'],
            'source_keyword': video_info.get('source_keyword', ''),
            'market': market,
            'ai_analysis': response.text,
            'success': True
        }
    except Exception as e:
        return {
            'video_id': video_info['id'],
            'title': video_title,
            'url': video_url,
            'view_count': video_info['view_count'],
            'source_keyword': video_info.get('source_keyword', ''),
            'market': market,
            'ai_analysis': f"çˆ¬å–å¤±æ•—: {str(e)}",
            'success': False
        }

def batch_extract_videos(api_key, videos_list, max_workers=3):
    """æ‰¹æ¬¡çˆ¬å–å¤šæ”¯å½±ç‰‡"""
    results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_video = {
            executor.submit(extract_video_content_via_ai, api_key, video): video 
            for video in videos_list
        }
        
        for future in concurrent.futures.as_completed(future_to_video):
            video = future_to_video[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                results.append({
                    'video_id': video['id'],
                    'title': video['title'],
                    'url': video['url'],
                    'view_count': video['view_count'],
                    'source_keyword': video.get('source_keyword', ''),
                    'market': video.get('market', 'zh'),
                    'ai_analysis': f"åŸ·è¡ŒéŒ¯èª¤: {str(e)}",
                    'success': False
                })
    
    return results

def analyze_search_intent_bilingual(api_key, zh_keywords, en_keywords, zh_videos, en_videos, model_version):
    """é›™èªå¸‚å ´æ„åœ–åˆ†æ"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_version)
    
    # æ•´ç†ä¸­æ–‡å¸‚å ´æ•¸æ“š
    zh_summary = ""
    if zh_videos:
        zh_summary = "\n### ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å¸‚å ´\n"
        for keyword in zh_keywords:
            keyword_videos = [v for v in zh_videos if v.get('source_keyword') == keyword]
            if keyword_videos:
                zh_summary += f"\n**é—œéµå­—ï¼šã€Œ{keyword}ã€**\n"
                for v in keyword_videos[:3]:
                    zh_summary += f"- {v['title']} (è§€çœ‹æ•¸: {v['view_count']:,})\n"
    
    # æ•´ç†è‹±æ–‡å¸‚å ´æ•¸æ“š
    en_summary = ""
    if en_videos:
        en_summary = "\n### ğŸ‡ºğŸ‡¸ è‹±æ–‡å¸‚å ´\n"
        for keyword in en_keywords:
            keyword_videos = [v for v in en_videos if v.get('source_keyword') == keyword]
            if keyword_videos:
                en_summary += f"\n**é—œéµå­—ï¼šã€Œ{keyword}ã€**\n"
                for v in keyword_videos[:3]:
                    en_summary += f"- {v['title']} (è§€çœ‹æ•¸: {v['view_count']:,})\n"

    prompt = f"""
    ä½ æ˜¯ä¸€å€‹è·¨èªè¨€æœå°‹æ„åœ–åˆ†æå°ˆå®¶ã€‚
    
    ä½¿ç”¨è€…ç ”ç©¶çš„ä¸­æ–‡é—œéµå­—ï¼š{', '.join(zh_keywords)}
    {'å°æ‡‰çš„è‹±æ–‡é—œéµå­—ï¼š' + ', '.join(en_keywords) if en_keywords else ''}
    
    ä»¥ä¸‹æ˜¯æœå°‹çµæœï¼š
    {zh_summary}
    {en_summary}
    
    è«‹åˆ†æï¼š
    
    ## 1. ã€æœå°‹æ„åœ–åˆ†æã€‘
    - é€™äº›é—œéµå­—èƒŒå¾Œçš„ä½¿ç”¨è€…éœ€æ±‚æ˜¯ä»€éº¼ï¼Ÿ
    - ä½¿ç”¨è€…æœ€æƒ³è§£æ±ºä»€éº¼å•é¡Œï¼Ÿ
    
    ## 2. ã€å¸‚å ´ç¾æ³ã€‘
    - ä¸­æ–‡å¸‚å ´ç›®å‰çš„å…§å®¹ä¸»è¦é›†ä¸­åœ¨å“ªäº›è§’åº¦ï¼Ÿ
    {'- è‹±æ–‡å¸‚å ´çš„å…§å®¹ä¸»è¦é›†ä¸­åœ¨å“ªäº›è§’åº¦ï¼Ÿ' if en_videos else ''}
    
    ## 3. ã€ä¸­è‹±å·®è·åˆ†æã€‘{'ï¼ˆé‡é»ï¼ï¼‰' if en_videos else 'ï¼ˆæœªå•Ÿç”¨è‹±æ–‡æœå°‹ï¼‰'}
    {'- è‹±æ–‡å¸‚å ´æœ‰ä½†ä¸­æ–‡å¸‚å ´ç¼ºä¹çš„å…§å®¹ä¸»é¡Œ' if en_videos else '- å»ºè­°å•Ÿç”¨è‹±æ–‡å¸‚å ´æœå°‹ä»¥ç²å¾—æ›´å®Œæ•´åˆ†æ'}
    {'- è‹±æ–‡å¸‚å ´çš„å…§å®¹æ·±åº¦/å°ˆæ¥­åº¦å·®ç•°' if en_videos else ''}
    {'- æœ€å€¼å¾—ã€Œæ¬é‹ã€åˆ°ä¸­æ–‡å¸‚å ´çš„å…§å®¹æ–¹å‘' if en_videos else ''}
    
    ## 4. ã€å…§å®¹æ©Ÿæœƒç¸½çµã€‘
    - ç¶œåˆä»¥ä¸Šåˆ†æï¼Œæœ€æœ‰æ½›åŠ›çš„å…§å®¹æ–¹å‘æ˜¯ï¼Ÿ
    
    è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼æ¸…æ™°ã€‚
    """
    
    response = model.generate_content(prompt)
    return response.text

def generate_strategy_module(api_key, module_key, all_analyses, keywords_info, user_goal, model_version, has_english=False):
    """ç”Ÿæˆå–®ä¸€ç­–ç•¥æ¨¡çµ„çš„å ±å‘Š"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_version)
    
    module = STRATEGY_MODULES[module_key]
    
    # æ•´ç†å½±ç‰‡åˆ†æå…§å®¹
    zh_analyses = [a for a in all_analyses if a.get('market') == 'zh']
    en_analyses = [a for a in all_analyses if a.get('market') == 'en']
    
    combined_context = ""
    
    if zh_analyses:
        combined_context += "### ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å¸‚å ´ç«¶å“\n\n"
        for idx, analysis in enumerate(zh_analyses, 1):
            combined_context += f"""
**[ä¸­æ–‡ {idx}] {analysis['title']}**
- ä¾†æºé—œéµå­—ï¼š{analysis.get('source_keyword', 'N/A')}
- è§€çœ‹æ•¸ï¼š{analysis['view_count']:,}
- ç¶²å€ï¼š{analysis['url']}

{analysis['ai_analysis']}

---
"""
    
    if en_analyses:
        combined_context += "\n### ğŸ‡ºğŸ‡¸ è‹±æ–‡å¸‚å ´ç«¶å“\n\n"
        for idx, analysis in enumerate(en_analyses, 1):
            combined_context += f"""
**[è‹±æ–‡ {idx}] {analysis['title']}**
- ä¾†æºé—œéµå­—ï¼š{analysis.get('source_keyword', 'N/A')}
- è§€çœ‹æ•¸ï¼š{analysis['view_count']:,}
- ç¶²å€ï¼š{analysis['url']}

{analysis['ai_analysis']}

---
"""

    # é‡å°æ¬é‹ç­–ç•¥çš„ç‰¹æ®Šè™•ç†
    localization_context = ""
    if module_key == "localization":
        if not en_analyses:
            return f"# {module['name']}\n\nâš ï¸ æœªå•Ÿç”¨è‹±æ–‡å¸‚å ´æœå°‹ï¼Œç„¡æ³•ç”Ÿæˆæ¬é‹ç­–ç•¥ã€‚è«‹åœ¨å´é‚Šæ¬„å•Ÿç”¨ã€Œè‹±æ–‡å¸‚å ´æ¯”å°ã€åŠŸèƒ½å¾Œé‡æ–°åŸ·è¡Œã€‚"
        localization_context = """
ç‰¹åˆ¥æ³¨æ„ï¼šè«‹é‡é»åˆ†æè‹±æ–‡å¸‚å ´çš„å½±ç‰‡ï¼Œæ‰¾å‡ºå€¼å¾—æœ¬åœ°åŒ–åˆ°ç¹é«”ä¸­æ–‡å¸‚å ´çš„å…§å®¹ã€‚
"""

    prompt = f"""
    ä½ æ˜¯ä¸€ä½é ‚å°–çš„ YouTube å…§å®¹ç­–ç•¥é¡§å•ã€‚
    
    ç ”ç©¶é—œéµå­—ï¼š{', '.join(keywords_info.get('zh', []))}
    {'å°æ‡‰è‹±æ–‡é—œéµå­—ï¼š' + ', '.join(keywords_info.get('en', [])) if keywords_info.get('en') else ''}
    
    ä»¥ä¸‹æ˜¯ç«¶å“å½±ç‰‡çš„è©³ç´°åˆ†æï¼š
    
    {combined_context}
    
    ã€ä½¿ç”¨è€…çš„å‰µä½œç›®æ¨™ã€‘
    {user_goal}
    
    {localization_context}
    
    è«‹æ ¹æ“šä»¥ä¸Šç«¶å“åˆ†æï¼Œå°ˆæ³¨æ–¼ä»¥ä¸‹ç­–ç•¥æ–¹å‘æå‡ºå»ºè­°ï¼š
    
    {module['prompt']}
    
    è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œå…§å®¹è¦å…·é«”å¯åŸ·è¡Œï¼Œæ ¼å¼æ¸…æ™°å°ˆæ¥­ã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        return f"# {module['name']}\n\n{response.text}"
    except Exception as e:
        return f"# {module['name']}\n\nâŒ ç”Ÿæˆå¤±æ•—: {str(e)}"

def batch_generate_strategies(api_key, selected_modules, all_analyses, keywords_info, user_goal, model_version, has_english=False):
    """ä¸¦è¡Œç”Ÿæˆå¤šå€‹ç­–ç•¥æ¨¡çµ„"""
    results = {}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(selected_modules)) as executor:
        future_to_module = {
            executor.submit(
                generate_strategy_module, 
                api_key, module_key, all_analyses, keywords_info, user_goal, model_version, has_english
            ): module_key 
            for module_key in selected_modules
        }
        
        for future in concurrent.futures.as_completed(future_to_module):
            module_key = future_to_module[future]
            try:
                result = future.result()
                results[module_key] = result
            except Exception as e:
                results[module_key] = f"# {STRATEGY_MODULES[module_key]['name']}\n\nâŒ åŸ·è¡ŒéŒ¯èª¤: {str(e)}"
    
    return results

# ==========================================
# 4. è¼”åŠ©å‡½å¼
# ==========================================

def generate_all_analyses_md(video_analyses):
    """å°‡æ‰€æœ‰å½±ç‰‡åˆ†ææ•´åˆæˆä¸€ä»½ Markdown"""
    zh_analyses = [a for a in video_analyses if a.get('market') == 'zh']
    en_analyses = [a for a in video_analyses if a.get('market') == 'en']
    
    content = f"# YouTube ç«¶å“å½±ç‰‡åˆ†æå ±å‘Š\n\n"
    content += f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    content += f"å…±åˆ†æ {len(video_analyses)} æ”¯å½±ç‰‡ï¼ˆä¸­æ–‡ {len(zh_analyses)} æ”¯ï¼Œè‹±æ–‡ {len(en_analyses)} æ”¯ï¼‰\n\n"
    content += "---\n\n"
    
    if zh_analyses:
        content += "## ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å¸‚å ´\n\n"
        for idx, analysis in enumerate(zh_analyses, 1):
            status = "âœ… æˆåŠŸ" if analysis['success'] else "âŒ å¤±æ•—"
            content += f"### {idx}. {analysis['title']}\n\n"
            content += f"- **ç‹€æ…‹**: {status}\n"
            content += f"- **ä¾†æºé—œéµå­—**: {analysis.get('source_keyword', 'N/A')}\n"
            content += f"- **ç¶²å€**: {analysis['url']}\n"
            content += f"- **è§€çœ‹æ•¸**: {analysis['view_count']:,}\n\n"
            content += f"#### åˆ†æå…§å®¹\n\n{analysis['ai_analysis']}\n\n"
            content += "---\n\n"
    
    if en_analyses:
        content += "## ğŸ‡ºğŸ‡¸ è‹±æ–‡å¸‚å ´\n\n"
        for idx, analysis in enumerate(en_analyses, 1):
            status = "âœ… æˆåŠŸ" if analysis['success'] else "âŒ å¤±æ•—"
            content += f"### {idx}. {analysis['title']}\n\n"
            content += f"- **ç‹€æ…‹**: {status}\n"
            content += f"- **ä¾†æºé—œéµå­—**: {analysis.get('source_keyword', 'N/A')}\n"
            content += f"- **ç¶²å€**: {analysis['url']}\n"
            content += f"- **è§€çœ‹æ•¸**: {analysis['view_count']:,}\n\n"
            content += f"#### åˆ†æå…§å®¹\n\n{analysis['ai_analysis']}\n\n"
            content += "---\n\n"
    
    return content

# ==========================================
# 5. Streamlit ä¸»ç¨‹å¼é‚è¼¯
# ==========================================

st.title("ğŸ¯ YouTube æˆ°ç•¥å…§å®¹åˆ‡å…¥åˆ†æå„€ v3")
st.caption("æ”¯æ´å¤šé—œéµå­—æœå°‹ â†’ ä¸­è‹±é›™èªå¸‚å ´æ¯”å° â†’ AI çˆ¬å–å­—å¹• â†’ æ¨¡çµ„åŒ–ç­–ç•¥ç”Ÿæˆ")

# Session State åˆå§‹åŒ–
if "confirmed_keywords" not in st.session_state:
    st.session_state.confirmed_keywords = []
if "english_keywords" not in st.session_state:
    st.session_state.english_keywords = {}  # {zh_keyword: en_keyword}
if "suggestions_cache" not in st.session_state:
    st.session_state.suggestions_cache = {}
if "search_results" not in st.session_state:
    st.session_state.search_results = {'zh': [], 'en': []}
if "intent_analysis" not in st.session_state:
    st.session_state.intent_analysis = ""
if "video_analyses" not in st.session_state:
    st.session_state.video_analyses = {'zh': [], 'en': []}
if "strategy_results" not in st.session_state:
    st.session_state.strategy_results = {}
if "user_goal" not in st.session_state:
    st.session_state.user_goal = "æˆ‘æƒ³åšä¸€æ”¯èƒ½è¹­åˆ°æµé‡ï¼Œä½†åœ¨å°ˆæ¥­åº¦ä¸Šè¶…è¶Šä»–å€‘çš„å½±ç‰‡"

# ============================================================
# STEP 1: é—œéµå­—è¼¸å…¥èˆ‡æœå°‹
# ============================================================
st.header("STEP 1ï½œé—œéµå­—æœå°‹èˆ‡å¸‚å ´æ„åœ–åˆ†æ")

with st.container(border=True):
    st.subheader("1-1. è¼¸å…¥èˆ‡ç®¡ç†é—œéµå­—")
    
    col_input, col_action = st.columns([3, 1])
    
    with col_input:
        new_keywords_input = st.text_area(
            "æ–°å¢é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼Œæˆ–ç”¨é€—è™Ÿåˆ†éš”ï¼‰",
            placeholder="AI å½±ç‰‡ç”Ÿæˆ\nAI å‰ªè¼¯å·¥å…·\nYouTube è‡ªå‹•åŒ–",
            height=80,
            key="new_keywords_input"
        )
    
    with col_action:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("â• åŠ å…¥é—œéµå­—åˆ—è¡¨", type="primary"):
            if new_keywords_input:
                new_kws = []
                for line in new_keywords_input.replace('ï¼Œ', ',').split('\n'):
                    for kw in line.split(','):
                        kw = kw.strip()
                        if kw and kw not in st.session_state.confirmed_keywords:
                            new_kws.append(kw)
                
                if new_kws:
                    st.session_state.confirmed_keywords.extend(new_kws)
                    st.success(f"å·²åŠ å…¥ {len(new_kws)} å€‹é—œéµå­—")
                    st.rerun()
                else:
                    st.warning("æ²’æœ‰æ–°çš„é—œéµå­—å¯åŠ å…¥")
    
    # é¡¯ç¤ºç›®å‰é—œéµå­—åˆ—è¡¨
    if st.session_state.confirmed_keywords:
        st.markdown("**ğŸ“‹ ç›®å‰é—œéµå­—åˆ—è¡¨ï¼š**")
        
        cols = st.columns(6)
        keywords_to_remove = []
        
        for idx, kw in enumerate(st.session_state.confirmed_keywords):
            with cols[idx % 6]:
                col_tag, col_x = st.columns([4, 1])
                with col_tag:
                    en_kw = st.session_state.english_keywords.get(kw, "")
                    if en_kw and ENABLE_ENGLISH:
                        st.markdown(f"`{kw}`\n`ğŸ‡ºğŸ‡¸ {en_kw}`")
                    else:
                        st.markdown(f"`{kw}`")
                with col_x:
                    if st.button("âœ•", key=f"del_{idx}", help=f"ç§»é™¤ {kw}"):
                        keywords_to_remove.append(kw)
        
        if keywords_to_remove:
            for kw in keywords_to_remove:
                st.session_state.confirmed_keywords.remove(kw)
                if kw in st.session_state.english_keywords:
                    del st.session_state.english_keywords[kw]
            st.rerun()
        
        col_clear, col_translate = st.columns(2)
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå…¨éƒ¨é—œéµå­—"):
                st.session_state.confirmed_keywords = []
                st.session_state.english_keywords = {}
                st.session_state.suggestions_cache = {}
                st.rerun()
        
        with col_translate:
            if ENABLE_ENGLISH:
                untranslated = [kw for kw in st.session_state.confirmed_keywords if kw not in st.session_state.english_keywords]
                if untranslated:
                    if st.button(f"ğŸŒ ç¿»è­¯é—œéµå­—ç‚ºè‹±æ–‡ ({len(untranslated)} å€‹)"):
                        if GEMINI_API_KEY:
                            with st.spinner("æ­£åœ¨ç¿»è­¯é—œéµå­—..."):
                                translations = batch_translate_keywords(GEMINI_API_KEY, untranslated)
                                st.session_state.english_keywords.update(translations)
                            st.rerun()
                        else:
                            st.error("è«‹å…ˆè¨­å®š Gemini API Key")
                else:
                    st.success("âœ… æ‰€æœ‰é—œéµå­—å·²ç¿»è­¯")
    else:
        st.info("å°šæœªåŠ å…¥ä»»ä½•é—œéµå­—ï¼Œè«‹åœ¨ä¸Šæ–¹è¼¸å…¥")

with st.container(border=True):
    st.subheader("1-2. å–å¾— YouTube å»ºè­°é—œéµå­—")
    st.caption("å‹¾é¸å»ºè­°é—œéµå­—æœƒè‡ªå‹•åŠ å…¥åˆ—è¡¨")
    
    if st.session_state.confirmed_keywords:
        keywords_without_suggestions = [
            kw for kw in st.session_state.confirmed_keywords 
            if kw not in st.session_state.suggestions_cache
        ]
        
        col_btn1, col_btn2, col_info = st.columns([1, 1, 2])
        
        with col_btn1:
            if st.button("ğŸ” å–å¾—æ–°é—œéµå­—çš„å»ºè­°", disabled=not keywords_without_suggestions):
                with st.spinner(f"æ­£åœ¨å–å¾— {len(keywords_without_suggestions)} å€‹é—œéµå­—çš„å»ºè­°..."):
                    for kw in keywords_without_suggestions:
                        suggestions = get_youtube_suggestions(kw)
                        st.session_state.suggestions_cache[kw] = suggestions
                st.rerun()
        
        with col_btn2:
            if st.button("ğŸ”„ é‡æ–°å–å¾—å…¨éƒ¨å»ºè­°"):
                with st.spinner("æ­£åœ¨é‡æ–°å–å¾—æ‰€æœ‰å»ºè­°..."):
                    st.session_state.suggestions_cache = {}
                    for kw in st.session_state.confirmed_keywords:
                        suggestions = get_youtube_suggestions(kw)
                        st.session_state.suggestions_cache[kw] = suggestions
                st.rerun()
        
        with col_info:
            if keywords_without_suggestions:
                st.caption(f"âš¡ {len(keywords_without_suggestions)} å€‹é—œéµå­—å°šæœªå–å¾—å»ºè­°")
            else:
                st.caption("âœ… æ‰€æœ‰é—œéµå­—éƒ½å·²å–å¾—å»ºè­°")
        
        if st.session_state.suggestions_cache:
            st.markdown("---")
            
            for base_kw, suggestions in st.session_state.suggestions_cache.items():
                if suggestions:
                    available_suggestions = [
                        s for s in suggestions 
                        if s not in st.session_state.confirmed_keywords
                    ]
                    
                    if available_suggestions:
                        st.markdown(f"**{base_kw}** çš„å»¶ä¼¸å»ºè­°ï¼š")
                        cols = st.columns(4)
                        for i, sug in enumerate(available_suggestions[:8]):
                            with cols[i % 4]:
                                if st.button(f"â• {sug}", key=f"add_sug_{base_kw}_{i}"):
                                    if sug not in st.session_state.confirmed_keywords:
                                        st.session_state.confirmed_keywords.append(sug)
                                        st.rerun()
                    else:
                        st.caption(f"**{base_kw}**ï¼šæ‰€æœ‰å»ºè­°éƒ½å·²åŠ å…¥åˆ—è¡¨")
    else:
        st.warning("è«‹å…ˆåœ¨ä¸Šæ–¹åŠ å…¥é—œéµå­—")

with st.container(border=True):
    st.subheader("1-3. åŸ·è¡Œæœå°‹")
    
    if st.session_state.confirmed_keywords:
        search_info = f"ğŸ¯ å°‡æœå°‹ {len(st.session_state.confirmed_keywords)} å€‹ä¸­æ–‡é—œéµå­—"
        if ENABLE_ENGLISH and st.session_state.english_keywords:
            search_info += f" + {len(st.session_state.english_keywords)} å€‹è‹±æ–‡é—œéµå­—"
        st.info(search_info)
        
        if st.button("ğŸš€ åŸ·è¡Œæ‰¹æ¬¡æœå°‹èˆ‡æ„åœ–åˆ†æ", type="primary"):
            if not GEMINI_API_KEY or not YOUTUBE_API_KEY:
                st.error("è«‹å…ˆåœ¨å·¦å´è¨­å®š API Key")
            else:
                # æœå°‹ä¸­æ–‡å¸‚å ´
                with st.spinner(f"æ­£åœ¨æœå°‹ä¸­æ–‡å¸‚å ´..."):
                    zh_results = search_multiple_keywords(
                        YOUTUBE_API_KEY, 
                        st.session_state.confirmed_keywords, 
                        MAX_RESULTS_PER_KEYWORD,
                        lang="zh"
                    )
                
                # æœå°‹è‹±æ–‡å¸‚å ´ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                en_results = []
                if ENABLE_ENGLISH and st.session_state.english_keywords:
                    with st.spinner(f"æ­£åœ¨æœå°‹è‹±æ–‡å¸‚å ´..."):
                        en_keywords = list(st.session_state.english_keywords.values())
                        en_results = search_multiple_keywords(
                            YOUTUBE_API_KEY, 
                            en_keywords, 
                            MAX_RESULTS_PER_KEYWORD,
                            lang="en"
                        )
                
                st.session_state.search_results = {'zh': zh_results, 'en': en_results}
                st.session_state.video_analyses = {'zh': [], 'en': []}
                st.session_state.strategy_results = {}
                
                if zh_results or en_results:
                    with st.spinner("æ­£åœ¨åˆ†ææœå°‹æ„åœ–..."):
                        en_keywords = list(st.session_state.english_keywords.values()) if ENABLE_ENGLISH else []
                        analysis = analyze_search_intent_bilingual(
                            GEMINI_API_KEY, 
                            st.session_state.confirmed_keywords,
                            en_keywords,
                            zh_results, 
                            en_results,
                            MODEL_VERSION
                        )
                        st.session_state.intent_analysis = analysis
                    st.rerun()
                else:
                    st.warning("æ‰¾ä¸åˆ°ç›¸é—œå½±ç‰‡")
    else:
        st.warning("è«‹å…ˆåŠ å…¥è‡³å°‘ä¸€å€‹é—œéµå­—")

# é¡¯ç¤ºæ„åœ–åˆ†æçµæœ
if st.session_state.intent_analysis:
    with st.container(border=True):
        st.subheader("ğŸ“Š å¸‚å ´æ„åœ–åˆ†æå ±å‘Š")
        st.markdown(st.session_state.intent_analysis)
        
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰æ„åœ–åˆ†æå ±å‘Š",
            st.session_state.intent_analysis,
            f"intent_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
            mime="text/markdown"
        )

# ============================================================
# STEP 2: é¸æ“‡ç«¶å“ & AI çˆ¬å–
# ============================================================
zh_results = st.session_state.search_results.get('zh', [])
en_results = st.session_state.search_results.get('en', [])

if zh_results or en_results:
    st.markdown("---")
    st.header("STEP 2ï½œé¸æ“‡ç«¶å“ & AI çˆ¬å–å½±ç‰‡å…§å®¹")
    st.caption(f"ğŸ’¡ å­—å¹•çˆ¬å–ä½¿ç”¨ `{TRANSCRIPT_MODEL}` æ¨¡å‹")
    
    with st.container(border=True):
        st.subheader("2-1. é¸æ“‡è¦åˆ†æçš„ç«¶å“å½±ç‰‡")
        
        selected_videos = []
        
        # ä¸­æ–‡å¸‚å ´å½±ç‰‡
        if zh_results:
            st.markdown("### ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å¸‚å ´")
            st.caption(f"å…± {len(zh_results)} æ”¯å½±ç‰‡")
            
            videos_by_keyword = {}
            for video in zh_results:
                kw = video.get('source_keyword', 'å…¶ä»–')
                if kw not in videos_by_keyword:
                    videos_by_keyword[kw] = []
                videos_by_keyword[kw].append(video)
            
            for keyword, videos in videos_by_keyword.items():
                with st.expander(f"ğŸ”‘ {keyword} ({len(videos)} æ”¯)", expanded=True):
                    cols = st.columns(3)
                    for idx, video in enumerate(videos):
                        with cols[idx % 3]:
                            st.image(video['thumbnail'], use_container_width=True)
                            title_display = video['title'][:35] + "..." if len(video['title']) > 35 else video['title']
                            st.markdown(f"**{title_display}**")
                            st.caption(f"ğŸ‘€ {video['view_count']:,} | [è§€çœ‹]({video['url']})")
                            if st.checkbox("ç´å…¥", key=f"vid_zh_{video['id']}"):
                                selected_videos.append(video)
        
        # è‹±æ–‡å¸‚å ´å½±ç‰‡
        if en_results:
            st.markdown("### ğŸ‡ºğŸ‡¸ è‹±æ–‡å¸‚å ´")
            st.caption(f"å…± {len(en_results)} æ”¯å½±ç‰‡")
            
            videos_by_keyword = {}
            for video in en_results:
                kw = video.get('source_keyword', 'å…¶ä»–')
                if kw not in videos_by_keyword:
                    videos_by_keyword[kw] = []
                videos_by_keyword[kw].append(video)
            
            for keyword, videos in videos_by_keyword.items():
                with st.expander(f"ğŸ”‘ {keyword} ({len(videos)} æ”¯)", expanded=True):
                    cols = st.columns(3)
                    for idx, video in enumerate(videos):
                        with cols[idx % 3]:
                            st.image(video['thumbnail'], use_container_width=True)
                            title_display = video['title'][:35] + "..." if len(video['title']) > 35 else video['title']
                            st.markdown(f"**{title_display}**")
                            st.caption(f"ğŸ‘€ {video['view_count']:,} | [è§€çœ‹]({video['url']})")
                            if st.checkbox("ç´å…¥", key=f"vid_en_{video['id']}"):
                                selected_videos.append(video)
        
        zh_selected = len([v for v in selected_videos if v.get('market') == 'zh'])
        en_selected = len([v for v in selected_videos if v.get('market') == 'en'])
        st.markdown(f"### âœ… å·²é¸æ“‡ {len(selected_videos)} å€‹ç«¶å“ï¼ˆä¸­æ–‡ {zh_selected}ï¼Œè‹±æ–‡ {en_selected}ï¼‰")
    
    with st.container(border=True):
        st.subheader("2-2. AI çˆ¬å–å½±ç‰‡å…§å®¹")
        
        if selected_videos:
            if st.button("ğŸ¤– é–‹å§‹ AI çˆ¬å–", type="primary"):
                if not GEMINI_API_KEY:
                    st.error("è«‹å…ˆè¨­å®š Gemini API Key")
                else:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    status_text.info(f"æ­£åœ¨ä½¿ç”¨ {TRANSCRIPT_MODEL} çˆ¬å– {len(selected_videos)} æ”¯å½±ç‰‡...")
                    
                    analyses = batch_extract_videos(
                        GEMINI_API_KEY, 
                        selected_videos,
                        max_workers=MAX_CONCURRENT_AI
                    )
                    
                    progress_bar.progress(100)
                    
                    # åˆ†é¡çµæœ
                    zh_analyses = [a for a in analyses if a.get('market') == 'zh']
                    en_analyses = [a for a in analyses if a.get('market') == 'en']
                    st.session_state.video_analyses = {'zh': zh_analyses, 'en': en_analyses}
                    
                    success_count = sum(1 for a in analyses if a['success'])
                    status_text.success(f"âœ… å®Œæˆï¼æˆåŠŸ {success_count}/{len(analyses)} æ”¯")
                    st.rerun()
        else:
            st.warning("è«‹å…ˆå‹¾é¸è‡³å°‘ä¸€å€‹å½±ç‰‡")
    
    # é¡¯ç¤ºçˆ¬å–çµæœ
    all_analyses = st.session_state.video_analyses.get('zh', []) + st.session_state.video_analyses.get('en', [])
    if all_analyses:
        with st.container(border=True):
            st.subheader("ğŸ“‹ å½±ç‰‡åˆ†æçµæœ")
            
            zh_analyses = st.session_state.video_analyses.get('zh', [])
            en_analyses = st.session_state.video_analyses.get('en', [])
            
            success_count = sum(1 for a in all_analyses if a['success'])
            st.caption(f"æˆåŠŸ {success_count}/{len(all_analyses)} æ”¯")
            
            if zh_analyses:
                st.markdown("#### ğŸ‡¹ğŸ‡¼ ä¸­æ–‡å½±ç‰‡åˆ†æ")
                for analysis in zh_analyses:
                    status_icon = "âœ…" if analysis['success'] else "âŒ"
                    with st.expander(f"{status_icon} [{analysis.get('source_keyword', '')}] {analysis['title'][:40]}"):
                        st.markdown(f"**ç¶²å€**: {analysis['url']}")
                        st.markdown(f"**è§€çœ‹æ•¸**: {analysis['view_count']:,}")
                        st.markdown("---")
                        st.markdown(analysis['ai_analysis'])
            
            if en_analyses:
                st.markdown("#### ğŸ‡ºğŸ‡¸ è‹±æ–‡å½±ç‰‡åˆ†æ")
                for analysis in en_analyses:
                    status_icon = "âœ…" if analysis['success'] else "âŒ"
                    with st.expander(f"{status_icon} [{analysis.get('source_keyword', '')}] {analysis['title'][:40]}"):
                        st.markdown(f"**ç¶²å€**: {analysis['url']}")
                        st.markdown(f"**è§€çœ‹æ•¸**: {analysis['view_count']:,}")
                        st.markdown("---")
                        st.markdown(analysis['ai_analysis'])
            
            st.markdown("---")
            all_analyses_md = generate_all_analyses_md(all_analyses)
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰å…¨éƒ¨å½±ç‰‡åˆ†æï¼ˆåˆä½µï¼‰",
                all_analyses_md,
                f"all_video_analyses_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                mime="text/markdown",
                type="primary"
            )

# ============================================================
# STEP 3: ç­–ç•¥æ¨¡çµ„ç”Ÿæˆ
# ============================================================
all_analyses = st.session_state.video_analyses.get('zh', []) + st.session_state.video_analyses.get('en', [])
if all_analyses:
    st.markdown("---")
    st.header("STEP 3ï½œç­–ç•¥æ¨¡çµ„ç”Ÿæˆ")
    
    with st.container(border=True):
        st.subheader("3-1. è¨­å®šå‰µä½œç›®æ¨™")
        user_goal = st.text_area(
            "æè¿°æ‚¨çš„å‰µä½œç›®æ¨™",
            value=st.session_state.user_goal,
            height=80,
            key="goal_input"
        )
        st.session_state.user_goal = user_goal
    
    with st.container(border=True):
        st.subheader("3-2. é¸æ“‡ç­–ç•¥æ¨¡çµ„")
        st.caption("å‹¾é¸è¦ç”Ÿæˆçš„ç­–ç•¥é¡å‹ï¼Œæ¯å€‹æ¨¡çµ„æœƒç”±ç¨ç«‹ AI åŒæ™‚è™•ç†")
        
        has_english = len(st.session_state.video_analyses.get('en', [])) > 0
        
        selected_modules = []
        
        cols = st.columns(3)
        for idx, (key, module) in enumerate(STRATEGY_MODULES.items()):
            with cols[idx % 3]:
                # æ¬é‹ç­–ç•¥éœ€è¦è‹±æ–‡è³‡æ–™
                disabled = (key == "localization" and not has_english)
                help_text = module['description']
                if key == "localization" and not has_english:
                    help_text += "ï¼ˆéœ€å•Ÿç”¨è‹±æ–‡å¸‚å ´æœå°‹ï¼‰"
                
                if st.checkbox(
                    module['name'], 
                    key=f"module_{key}",
                    disabled=disabled,
                    help=help_text
                ):
                    selected_modules.append(key)
        
        st.markdown(f"**å·²é¸æ“‡ {len(selected_modules)} å€‹ç­–ç•¥æ¨¡çµ„**")
        
        if not has_english:
            st.info("ğŸ’¡ å•Ÿç”¨ã€Œè‹±æ–‡å¸‚å ´æ¯”å°ã€åŠŸèƒ½å¯è§£é–ã€Œæ¬é‹ç­–ç•¥ã€æ¨¡çµ„")
    
    with st.container(border=True):
        st.subheader("3-3. ç”Ÿæˆç­–ç•¥")
        st.caption(f"ä½¿ç”¨ `{MODEL_VERSION}` æ¨¡å‹ï¼Œ{len(selected_modules)} å€‹ AI å°‡åŒæ™‚é‹ä½œ")
        
        if selected_modules:
            if st.button("ğŸš€ ç”Ÿæˆç­–ç•¥å ±å‘Š", type="primary"):
                with st.spinner(f"æ­£åœ¨åŒæ™‚åŸ·è¡Œ {len(selected_modules)} å€‹ç­–ç•¥åˆ†æ..."):
                    keywords_info = {
                        'zh': st.session_state.confirmed_keywords,
                        'en': list(st.session_state.english_keywords.values()) if st.session_state.english_keywords else []
                    }
                    
                    results = batch_generate_strategies(
                        GEMINI_API_KEY,
                        selected_modules,
                        all_analyses,
                        keywords_info,
                        user_goal,
                        MODEL_VERSION,
                        has_english
                    )
                    st.session_state.strategy_results = results
                    st.rerun()
        else:
            st.warning("è«‹å…ˆé¸æ“‡è‡³å°‘ä¸€å€‹ç­–ç•¥æ¨¡çµ„")
    
    # é¡¯ç¤ºç­–ç•¥çµæœ
    if st.session_state.strategy_results:
        with st.container(border=True):
            st.subheader("ğŸ¯ ç­–ç•¥å ±å‘Š")
            
            # å»ºç«‹ tabs é¡¯ç¤ºå„ç­–ç•¥
            tab_names = [STRATEGY_MODULES[key]['name'] for key in st.session_state.strategy_results.keys()]
            tabs = st.tabs(tab_names)
            
            for tab, (key, content) in zip(tabs, st.session_state.strategy_results.items()):
                with tab:
                    st.markdown(content)
                    st.download_button(
                        f"ğŸ“¥ ä¸‹è¼‰ {STRATEGY_MODULES[key]['name']}",
                        content,
                        f"strategy_{key}_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                        mime="text/markdown",
                        key=f"dl_strategy_{key}"
                    )

# ============================================================
# å…¨éƒ¨ä¸‹è¼‰å€
# ============================================================
if st.session_state.strategy_results:
    st.markdown("---")
    st.header("ğŸ“¦ ä¸€éµä¸‹è¼‰å…¨éƒ¨")
    
    with st.container(border=True):
        full_report = f"# YouTube æˆ°ç•¥å…§å®¹åˆ†æå®Œæ•´å ±å‘Š\n\n"
        full_report += f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        full_report += f"ç ”ç©¶é—œéµå­—ï¼ˆä¸­æ–‡ï¼‰ï¼š{', '.join(st.session_state.confirmed_keywords)}\n"
        if st.session_state.english_keywords:
            full_report += f"ç ”ç©¶é—œéµå­—ï¼ˆè‹±æ–‡ï¼‰ï¼š{', '.join(st.session_state.english_keywords.values())}\n"
        full_report += "\n---\n\n"
        
        full_report += "# PART 1: å¸‚å ´æ„åœ–åˆ†æ\n\n"
        full_report += st.session_state.intent_analysis + "\n\n"
        full_report += "---\n\n"
        
        all_analyses = st.session_state.video_analyses.get('zh', []) + st.session_state.video_analyses.get('en', [])
        full_report += "# PART 2: ç«¶å“å½±ç‰‡åˆ†æ\n\n"
        full_report += generate_all_analyses_md(all_analyses)
        full_report += "\n---\n\n"
        
        full_report += "# PART 3: ç­–ç•¥å ±å‘Š\n\n"
        for key, content in st.session_state.strategy_results.items():
            full_report += content + "\n\n---\n\n"
        
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±å‘Šï¼ˆå«æ‰€æœ‰åˆ†æï¼‰",
            full_report,
            f"youtube_full_report_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
            mime="text/markdown",
            type="primary"
        )
        
        st.caption("åŒ…å«ï¼šå¸‚å ´æ„åœ–åˆ†æ + æ‰€æœ‰å½±ç‰‡åˆ†æ + å…¨éƒ¨ç­–ç•¥å ±å‘Š")
