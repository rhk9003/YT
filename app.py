import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter
import google.generativeai as genai
import time
import json
import io
from concurrent.futures import ThreadPoolExecutor, as_completed

# =================================================
# 1. Page Config & Session State
# =================================================
st.set_page_config(
    page_title="YouTube æˆ°ç•¥é›·é” v4.1 (Debugç‰ˆ)",
    page_icon="ğŸ¬",
    layout="wide"
)

# åˆå§‹åŒ– Session State ä»¥ä¿å­˜æœå°‹çµæœä¾›ç¬¬äºŒéšæ®µä½¿ç”¨
if 'search_results' not in st.session_state:
    st.session_state.search_results = None
if 'landscape_analysis' not in st.session_state:
    st.session_state.landscape_analysis = None

st.title("ğŸ¬ YouTube æˆ°ç•¥é›·é” v4.1 (Debug Mode)")
st.markdown("""
### Private Content Weapon: YT Narrative Strategy
**Phase 1: æœå°‹æ„åœ–åµå¯Ÿ (Landscape) â†’ Phase 2: ç«¶å“æ·±åº¦è§£æ§‹ (Deep Dive)**
""")

# =================================================
# 2. Sidebar & API Setup
# =================================================
with st.sidebar:
    st.header("ğŸ”‘ API è¨­å®š")
    YOUTUBE_API_KEY = st.text_input("YouTube Data API Key", type="password", help="éœ€å•Ÿç”¨ YouTube Data API v3")
    GEMINI_API_KEY = st.text_input("Gemini API Key", type="password")

    st.divider()
    st.header("ğŸ§  æ¨¡å‹è¨­å®š")
    MODEL_NAME = st.selectbox(
        "åˆ†ææ¨¡å‹",
        ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3-pro-preview"],
        index=0,
        help="å»ºè­°ï¼šFlash ç”¨æ–¼ç¬¬ä¸€éšæ®µå¿«é€Ÿæƒæï¼ŒPro ç”¨æ–¼ç¬¬äºŒéšæ®µæ·±åº¦è…³æœ¬åˆ†æ"
    )

    st.divider()
    st.header("ğŸ” æœå°‹åƒæ•¸")
    MAX_RESULTS = st.slider("æŠ“å–å½±ç‰‡æ•¸", 5, 20, 10)
    REGION_CODE = st.text_input("åœ°å€ (Region)", value="TW")
    RELEVANCE_LANG = st.text_input("èªè¨€ (Relevance)", value="zh-Hant")

# =================================================
# 3. Core Logic Functions
# =================================================

def get_video_transcripts(video_id):
    """å˜—è©¦æŠ“å–å½±ç‰‡å­—å¹•ï¼Œå„ªå…ˆæŠ“ç¹ä¸­ï¼Œå…¶æ¬¡ç°¡ä¸­/è‹±æ–‡ï¼Œè‹¥ç„¡å‰‡å›å‚³ç©ºå­—ä¸²"""
    try:
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        # å„ªå…ˆé †åºï¼šæ‰‹å‹•ç¹ä¸­ -> æ‰‹å‹•ä¸­æ–‡ -> è‡ªå‹•ç¹ä¸­ -> è‡ªå‹•ä¸­æ–‡ -> è‹±æ–‡
        try:
            transcript = transcript_list.find_transcript(['zh-TW', 'zh-Hant', 'zh', 'en'])
        except:
            # å¦‚æœæ‰¾ä¸åˆ°æŒ‡å®šèªè¨€ï¼Œå°±æŠ“åŸæœ¬ç”Ÿæˆçš„ä»»ä½•èªè¨€
            transcript = transcript_list.find_generated_transcript(['zh-TW', 'zh-Hant', 'zh', 'en'])
        
        formatter = TextFormatter()
        return formatter.format_transcript(transcript.fetch())
    except Exception:
        return "" # ç„¡æ³•æŠ“å–å­—å¹•ï¼ˆå¯èƒ½æœªæä¾›æˆ–è¢«åœç”¨ï¼‰

def fetch_youtube_data(api_key, keyword, max_results):
    """ç¬¬ä¸€éšæ®µï¼šæœå°‹ä¸¦ç²å–åŸºæœ¬è³‡æ–™ + å­—å¹• (å«éŒ¯èª¤æ•æ‰)"""
    try:
        youtube = build('youtube', 'v3', developerKey=api_key)
        
        # 1. æœå°‹å½±ç‰‡ ID
        search_response = youtube.search().list(
            q=keyword,
            part='id,snippet',
            maxResults=max_results,
            type='video',
            regionCode=REGION_CODE,
            relevanceLanguage=RELEVANCE_LANG
        ).execute()

        video_ids = [item['id']['videoId'] for item in search_response['items']]
        
        if not video_ids:
            st.warning("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½•ç›¸é—œå½±ç‰‡ï¼Œè«‹å˜—è©¦æ›´æ›é—œéµå­—æˆ–æ”¾å¯¬æœå°‹æ¢ä»¶ã€‚")
            return None

        videos_data = []

        # 2. ç²å–å½±ç‰‡è©³ç´°æ•¸æ“š (çµ±è¨ˆæ•¸æ“š)
        stats_response = youtube.videos().list(
            part='statistics,contentDetails,snippet',
            id=','.join(video_ids)
        ).execute()

        # 3. æ•´åˆæ•¸æ“šä¸¦ä¸¦è¡ŒæŠ“å–å­—å¹•
        # ä½¿ç”¨ ThreadPool åŠ é€Ÿå­—å¹•ä¸‹è¼‰
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_vid = {executor.submit(get_video_transcripts, vid): vid for vid in video_ids}
            
            transcripts_map = {}
            for future in as_completed(future_to_vid):
                vid = future_to_vid[future]
                transcripts_map[vid] = future.result()

        for item in stats_response['items']:
            vid = item['id']
            snippet = item['snippet']
            stats = item['statistics']
            
            # è™•ç†éé•·çš„æè¿°
            full_desc = snippet.get('description', '')
            
            videos_data.append({
                "VideoID": vid,
                "Title": snippet.get('title'),
                "Channel": snippet.get('channelTitle'),
                "PublishDate": snippet.get('publishedAt')[:10],
                "Views": int(stats.get('viewCount', 0)),
                "Likes": int(stats.get('likeCount', 0)),
                "Comments": int(stats.get('commentCount', 0)),
                "URL": f"https://www.youtube.com/watch?v={vid}",
                "Description": full_desc,
                "HasCC": "âœ…" if transcripts_map.get(vid) else "âŒ",
                "Transcript_Full": transcripts_map.get(vid, "")
            })

        return pd.DataFrame(videos_data)

    except Exception as e:
        st.error(f"âŒ YouTube API é€£ç·šéŒ¯èª¤ï¼š{str(e)}")
        st.info("ğŸ’¡ å¸¸è¦‹åŸå› ï¼š\n1. API Key æœªå•Ÿç”¨ 'YouTube Data API v3'\n2. API Key è¤‡è£½éŒ¯èª¤\n3. æ¯æ—¥é…é¡å·²æ»¿")
        return None

def analyze_landscape(api_key, model_name, keyword, df):
    """Phase 1 åˆ†æï¼šæœå°‹æ„åœ–èˆ‡æˆ°å ´æ¦‚æ³"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    
    # æº–å‚™ç°¡åŒ–ç‰ˆè³‡æ–™çµ¦ AI (ä¸å«å®Œæ•´å­—å¹•ï¼Œé¿å… Token çˆ†ç‚¸)
    summary_data = df[["Title", "Channel", "Views", "Description"]].to_string(index=False)

    prompt = f"""
    ä½ æ˜¯ä¸€ä½ YouTube å…§å®¹ç­–ç•¥å°ˆå®¶ã€‚è«‹é‡å°é—œéµå­—ã€Œ{keyword}ã€çš„æœå°‹çµæœé€²è¡Œã€Œæˆ°å ´åµå¯Ÿã€ã€‚
    
    æœå°‹çµæœæ•¸æ“šï¼š
    {summary_data}

    è«‹ä»¥ JSON æ ¼å¼å›å‚³åˆ†æçµæœï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
    {{
        "Search_Intent": "ä½¿ç”¨è€…æœå°‹é€™å€‹è©ï¼ŒèƒŒå¾ŒçœŸæ­£çš„å¿ƒç†éœ€æ±‚æ˜¯ä»€éº¼ï¼Ÿï¼ˆå¨›æ¨‚/å­¸ç¿’/è§£æ±ºå•é¡Œ/æ†¤æ€’å®£æ´©...ï¼‰",
        "Content_Saturation": "ç›®å‰çš„å…§å®¹æ˜¯å¦é£½å’Œï¼Ÿä¸»è¦æ˜¯å“ªé¡å½¢å¼ï¼ˆTalking head/Vlog/æ•™å­¸éŒ„å±...ï¼‰ï¼Ÿ",
        "Audience_Gap": "è§€çœ¾å¯èƒ½é‚„æƒ³çœ‹ä»€éº¼ï¼Œä½†ç›®å‰çš„å½±ç‰‡æ²’æœ‰æ»¿è¶³çš„ï¼Ÿ",
        "Thumbnail_Strategy": "è§€å¯Ÿæ¨™é¡Œï¼Œç›®å‰çš„é»æ“Šèª˜é¤Œï¼ˆClickbaitï¼‰ä¸»è¦æ˜¯åˆ©ç”¨ä»€éº¼å¿ƒç†ï¼Ÿ"
    }}
    è«‹ç›´æ¥å›å‚³ JSONï¼Œä¸è¦ markdownã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        return {"error": str(e)}

def analyze_deep_dive(api_key, model_name, selected_rows):
    """Phase 2 åˆ†æï¼šé‡å°é¸å®šå½±ç‰‡çš„æ·±åº¦æˆ°è¡“"""
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    
    # çµ„åˆ Promptï¼ŒåŒ…å«å…·é«”å­—å¹•å…§å®¹
    context_text = ""
    for idx, row in selected_rows.iterrows():
        # æˆªæ–·éé•·çš„å­—å¹•ä»¥ç¯€çœ Token (æ¯éƒ¨å½±ç‰‡å–å‰ 3000 å­—)
        transcript_snippet = row['Transcript_Full'][:3000] + "..." if len(row['Transcript_Full']) > 3000 else row['Transcript_Full']
        context_text += f"""
        ---
        å½±ç‰‡æ¨™é¡Œï¼š{row['Title']}
        è§€çœ‹æ¬¡æ•¸ï¼š{row['Views']}
        é »é“ï¼š{row['Channel']}
        å½±ç‰‡å­—å¹•/å…§å®¹æ‘˜è¦ï¼š
        {transcript_snippet}
        ---
        """

    prompt = f"""
    ä½ ç¾åœ¨æ˜¯æˆ‘çš„é¦–å¸­å…§å®¹ç­–åŠƒã€‚æˆ‘æŒ‘é¸äº†ä»¥ä¸Šå¹¾éƒ¨ç«¶çˆ­å°æ‰‹/åƒè€ƒå½±ç‰‡ã€‚
    æˆ‘è¦åšä¸€æ”¯å½±ç‰‡ä¾†åˆ‡å…¥é€™å€‹å¸‚å ´ã€‚
    è«‹æ ¹æ“šä¸Šè¿°å½±ç‰‡çš„å…·é«”å…§å®¹ï¼ˆå­—å¹•é‚è¼¯ï¼‰ï¼Œç‚ºæˆ‘ç”Ÿæˆä¸‰ç¨®ä¸åŒç¶­åº¦çš„ã€Œé€²æ”»ç­–ç•¥ã€ï¼š

    åƒè€ƒè³‡æ–™ï¼š
    {context_text}

    è«‹å›å‚³ JSON æ ¼å¼ï¼š
    {{
        "Strategy_1_Relate": {{
            "Concept": "ç›¸é—œåˆ‡å…¥ï¼ˆè¹­ç†±åº¦/é †å‹¢ï¼‰",
            "Angle": "å¦‚ä½•åˆ©ç”¨é€™äº›å½±ç‰‡å»ºç«‹çš„èªçŸ¥åŸºç¤ï¼Œé †è‘—è¬›ä½†æä¾›æ›´å¥½å¸æ”¶çš„ç‰ˆæœ¬ï¼Ÿ",
            "Hook": "å»ºè­°çš„é–‹å ´ç™½ï¼ˆHookï¼‰"
        }},
        "Strategy_2_Extend": {{
            "Concept": "å»¶ä¼¸åˆ‡å…¥ï¼ˆè£œå®Œ/æ·±æŒ–ï¼‰",
            "Angle": "é€™äº›å½±ç‰‡å¿½ç•¥äº†ä»€éº¼ç´°ç¯€ï¼Ÿæˆ–æ˜¯å“ªå€‹è§€é»å¯ä»¥å†å¾€ä¸‹æŒ–æ·±ä¸€å±¤ï¼Ÿ",
            "Hook": "å»ºè­°çš„é–‹å ´ç™½ï¼ˆHookï¼‰"
        }},
        "Strategy_3_Transcend": {{
            "Concept": "è¶…è¶Šåˆ‡å…¥ï¼ˆåè§€é»/é™ç¶­æ‰“æ“Šï¼‰",
            "Angle": "å¦‚ä½•æå‡ºä¸€å€‹å®Œå…¨ä¸åŒã€ç”šè‡³æ¨ç¿»ä¸Šè¿°å½±ç‰‡é‚è¼¯çš„æ–°è§€é»ï¼Ÿ",
            "Hook": "å»ºè­°çš„é–‹å ´ç™½ï¼ˆHookï¼‰"
        }},
        "Common_Weakness": "é€™å¹¾éƒ¨å½±ç‰‡åœ¨æ•˜äº‹æˆ–é‚è¼¯ä¸Šå…±åŒçš„å¼±é»æ˜¯ä»€éº¼ï¼Ÿ"
    }}
    è«‹ç›´æ¥å›å‚³ JSONï¼Œä¸è¦ markdownã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        text = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except Exception as e:
        return {"error": str(e)}

# =================================================
# 4. Main UI Flow
# =================================================

# --- Input Section ---
st.subheader("ğŸ“¡ Phase 1: æˆ°å ´æƒæ (Landscape Scan)")
col1, col2 = st.columns([3, 1])
with col1:
    keyword_input = st.text_input("è¼¸å…¥ç›®æ¨™é—œéµå­—", placeholder="ä¾‹å¦‚ï¼šAI è¡ŒéŠ·å·¥å…·, æ¸›è„‚é¤, æŠ•è³‡å¿ƒæ³•")
with col2:
    search_btn = st.button("ğŸš€ åŸ·è¡Œåµå¯Ÿ", type="primary", use_container_width=True)

# --- Phase 1 Execution ---
if search_btn and keyword_input and YOUTUBE_API_KEY and GEMINI_API_KEY:
    with st.spinner("æ­£åœ¨çˆ¬å– YouTube è³‡æ–™ã€ä¸‹è¼‰å­—å¹•ä¸¦é€²è¡Œåˆæ­¥åˆ†æ..."):
        # 1. çˆ¬å– (å¦‚æœå¤±æ•—æœƒå›å‚³ None)
        df_result = fetch_youtube_data(YOUTUBE_API_KEY, keyword_input, MAX_RESULTS)
        
        if df_result is not None:
            st.session_state.search_results = df_result
            
            # 2. åˆ†æ
            analysis = analyze_landscape(GEMINI_API_KEY, MODEL_NAME, keyword_input, df_result)
            st.session_state.landscape_analysis = analysis
        else:
            # å¦‚æœçˆ¬å–å¤±æ•—ï¼Œæ¸…ç©ºä¹‹å‰çš„çµæœé¿å…æ··æ·†
            st.session_state.search_results = None
            st.session_state.landscape_analysis = None

# --- Phase 1 Display ---
if st.session_state.search_results is not None:
    df = st.session_state.search_results
    analysis = st.session_state.landscape_analysis
    
    # é¡¯ç¤ºæ•´é«”æˆ°ç•¥åˆ†æ
    if analysis and "error" not in analysis:
        st.success("âœ… æˆ°å ´åµå¯Ÿå®Œæˆ")
        with st.expander("ğŸ“Š æœå°‹æ„åœ–èˆ‡æˆ°å ´å ±å‘Š", expanded=True):
            ac1, ac2 = st.columns(2)
            with ac1:
                st.markdown(f"**ğŸ¯ æœå°‹æ„åœ–**\n\n{analysis.get('Search_Intent', 'N/A')}")
                st.markdown(f"**ğŸ“‰ è§€çœ¾ç¼ºå£**\n\n{analysis.get('Audience_Gap', 'N/A')}")
            with ac2:
                st.markdown(f"**ğŸ”¥ å…§å®¹é£½å’Œåº¦**\n\n{analysis.get('Content_Saturation', 'N/A')}")
                st.markdown(f"**ğŸ£ å°é¢èˆ‡æ¨™é¡Œç­–ç•¥**\n\n{analysis.get('Thumbnail_Strategy', 'N/A')}")
    elif analysis:
        st.error(f"AI åˆ†æç™¼ç”ŸéŒ¯èª¤: {analysis.get('error')}")

    st.divider()
    
    # --- Phase 2 Input: Selection ---
    st.subheader("âš”ï¸ Phase 2: æˆ°è¡“é–å®š (Tactical Targeting)")
    st.info("è«‹å‹¾é¸æ‚¨æƒ³ã€Œå°æ¨™ã€ã€ã€Œæ¨¡ä»¿ã€æˆ–ã€Œè¶…è¶Šã€çš„å½±ç‰‡ï¼ˆå»ºè­°é¸ 1-3 éƒ¨å…·æœ‰ä»£è¡¨æ€§æˆ–é«˜æµé‡çš„å½±ç‰‡ï¼‰ï¼š")

    # è£½ä½œä¸€å€‹ä¾›é¸æ“‡çš„ DataFrame view (éš±è—å¤ªé•·çš„æ¬„ä½)
    display_df = df[["HasCC", "Title", "Channel", "Views", "PublishDate", "URL"]].copy()
    display_df.insert(0, "Select", False)
    
    # ä½¿ç”¨ Data Editor è®“ä½¿ç”¨è€…å‹¾é¸
    edited_df = st.data_editor(
        display_df,
        column_config={
            "Select": st.column_config.CheckboxColumn("é–å®š", help="å‹¾é¸ä»¥é€²è¡Œæ·±åº¦åˆ†æ", default=False),
            "URL": st.column_config.LinkColumn("é€£çµ"),
            "HasCC": st.column_config.TextColumn("å­—å¹•", help="æ˜¯å¦æœ‰æŠ“åˆ°å­—å¹•å…§å®¹")
        },
        disabled=["HasCC", "Title", "Channel", "Views", "PublishDate", "URL"],
        hide_index=True,
        use_container_width=True
    )

    # æ‰¾å‡ºè¢«å‹¾é¸çš„åŸå§‹è³‡æ–™
    selected_indices = [i for i, row in edited_df.iterrows() if row['Select']]
    selected_rows = df.iloc[selected_indices]

    if not selected_rows.empty:
        st.write(f"å·²é–å®š {len(selected_rows)} éƒ¨å½±ç‰‡ï¼Œæº–å‚™é€²è¡Œæ·±åº¦è…³æœ¬åˆ†æ...")
        
        if st.button("âš¡ ç”Ÿæˆé€²æ”»è…³æœ¬ç­–ç•¥"):
            # æª¢æŸ¥æ˜¯å¦æœ‰å­—å¹•è³‡æ–™
            cc_count = selected_rows[selected_rows['Transcript_Full'] != ""].shape[0]
            if cc_count == 0:
                st.warning("âš ï¸ è­¦å‘Šï¼šæ‚¨é¸çš„å½±ç‰‡éƒ½æ²’æœ‰æŠ“åˆ°å­—å¹•/é€å­—ç¨¿ï¼ŒAI åˆ†æå°‡åƒ…åŸºæ–¼æ¨™é¡Œèˆ‡æè¿°ï¼Œæº–ç¢ºåº¦æœƒä¸‹é™ã€‚")
            
            with st.spinner("Gemini æ­£åœ¨é–±è®€å½±ç‰‡é€å­—ç¨¿ä¸¦æ“¬å®šä½œæˆ°è¨ˆç•«..."):
                strategy = analyze_deep_dive(GEMINI_API_KEY, MODEL_NAME, selected_rows)
            
            if strategy and "error" not in strategy:
                st.markdown("### ğŸ“ ä½œæˆ°è¨ˆç•«æ›¸")
                
                tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¤ é †å‹¢ç›¸é—œ", "ğŸ” å»¶ä¼¸è£œå®Œ", "ğŸ’¥ é™ç¶­è¶…è¶Š", "âš ï¸ å…±åŒå¼±é»"])
                
                with tab1:
                    s1 = strategy.get("Strategy_1_Relate", {})
                    st.markdown(f"#### {s1.get('Concept')}")
                    st.info(f"**åˆ‡å…¥é»**ï¼š{s1.get('Angle')}")
                    st.markdown(f"> **ğŸª Killer Hook**: {s1.get('Hook')}")
                    
                with tab2:
                    s2 = strategy.get("Strategy_2_Extend", {})
                    st.markdown(f"#### {s2.get('Concept')}")
                    st.success(f"**åˆ‡å…¥é»**ï¼š{s2.get('Angle')}")
                    st.markdown(f"> **ğŸª Killer Hook**: {s2.get('Hook')}")

                with tab3:
                    s3 = strategy.get("Strategy_3_Transcend", {})
                    st.markdown(f"#### {s3.get('Concept')}")
                    st.warning(f"**åˆ‡å…¥é»**ï¼š{s3.get('Angle')}")
                    st.markdown(f"> **ğŸª Killer Hook**: {s3.get('Hook')}")

                with tab4:
                    st.markdown(f"#### ğŸ›¡ï¸ å°æ‰‹é˜²ç¦¦ç¼ºå£")
                    st.error(strategy.get("Common_Weakness", "ç„¡æ˜é¡¯å¼±é»"))

                # é¡¯ç¤º JSON ä¾›è¤‡è£½
                with st.expander("æŸ¥çœ‹åŸå§‹ JSON"):
                    st.json(strategy)

            elif strategy:
                st.error(f"åˆ†æå¤±æ•—: {strategy.get('error')}")

    # --- è®“ä½¿ç”¨è€…ä¸‹è¼‰åŸå§‹è³‡æ–™ ---
    st.divider()
    csv_buffer = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        "ğŸ“¥ ä¸‹è¼‰æœå°‹çµæœèˆ‡å­—å¹• (CSV)",
        data=csv_buffer,
        file_name=f"yt_strategy_{int(time.time())}.csv",
        mime="text/csv"
    )

elif st.session_state.search_results is None and search_btn:
    # é€™è£¡é€šå¸¸æ˜¯ API éŒ¯èª¤ç™¼ç”Ÿå¾Œæœƒèµ°åˆ°çš„åœ°æ–¹ï¼Œå› ç‚º df_result ç‚º None
    pass
